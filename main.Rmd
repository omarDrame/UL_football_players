---
title: "Statistical learing HW 1"
author: "Dramé Omar"
date: '17/10/2022'
output:
  html_document: 
    css: my-theme.css
    theme: cerulean
    highlight: tango
    number_sections: no
    toc: no
    toc_depth: 1
  pdf_document:
    css: my-theme.css
    theme: cerulean
    highlight: tango
    number_sections: yes
    toc: yes
    toc_depth: 1
editor_options:
  chunk_output_type: console
---

# The motivation
The goal of this notebook is to be able to anticipate the position of an unknown or new player only using his statistics and skills. With that we could be able to see if some players should be playing at other position for example.

```{r}
library(leaflet)
library(rgdal)
library(stringr)
library(tidyverse)
library(GGally) 
library(factoextra) 
library(cluster)
library(mclust)
library(kernlab)
library(igraph)
```

# The data set
We start by getting the raw data from this website : https://www.kaggle.com/datasets/vivovinco/20212022-football-player-stats.
We have here data about the 2021-2022 football season. There is information about individual players in the 5 biggest Europeans competitions, Premier League England, Ligue 1 France, Bundesliga Germany, Serie A Italie and La Liga Spain. The season contain 38 or 36 games and most of the variables are for 90 minutes (per games).

```{r}
raw_data = read.csv(file = "FootballPlayers.csv",header = FALSE,sep = ',', fileEncoding="latin1")
```

We can look at the raw data to have an idea about the data set with the function glimpse, With dim wee see that there are 143 variables mostly doubles and 2921 rows or players which is huge (for me).

```{r}
glimpse(raw_data)
dim(raw_data)
```

## Notes about the data set
We're going to define some variables and values.

The values for the position of a player are the following :
- FW Forward player
- MF Middle field player
- DF Defensive player

Note that a player can have multiple positions.


The meaning of the variables :
- "matches_started"   : Number of games where the player was in the initial 11 in the season 
- "min_played"        : Average time played per game
- "goals"             : Average number of goals per game
- "shots"             : Average number of attempted shots per game
- "passes"            : Average number of attempted passes per game
- "good_passes"       : Average number of successful shots per game
- "assists"           : Average number of passes (of any kind) before another player scores per game
- "crosses"           : Average number of attempted crosses per game
- "tackles"           : Average number of attempted tackles per game
- "good_tackles"      : Average number of successful tackles per game
- "interceptions"     : Average number of ball interceptions per game
- "clearances"        : Average number of ball clearances per game
- " def_touches"      : Average number of ball touches in the 1/3 defensive field per game
- "at_touches"        : Average number of ball touches in the 1/3 offensive field per game
- "dribbles"          : Average number of attempted dribbles per game
- "good_dribles"      : Average number of successful dribbles per game
- "fouls_drawn"       : Average number of fouls done to the player per game
- "areal_wins"        : Average number of ball touches in the air against position
- "dribbles_goal"     : Average number of dribbles that led to a goal per game
- "goal_action"       : Average number of actions that led to a goal per game
- "shots_target"      : Average number of shots on target per game

# Data preprocessing

## Feature engineering
There are a lot of variables taken into account, 143 seems too much so let's try to keep the most useful ones. We don't keep the variable that are judged non-relevant to the subject, we also delete variable that can be deduced from other ones by simple calculus like additions and multiplications.

We will define 2 data sets, the 1st one is just to have information that are non numerical, like name and id. The second one is the one we will work with mostly, it will only contain 21 variables:

```{r}
players = raw_data %>% select(c(1,2,4,7,12))
colnames(players) = c("id","name","position","age","min_played")


players.df = raw_data %>% select(c(V10,V12,V13,V14,V24,V23,V37,V135,V82,V83,V101,V103,V107,V109,V112,V113,V133,V143,V78,V75,V15))
colnames(players.df) = c("matches_started","min_played","goals","shots","passes","good_passes","assists","crosses","tackles","good_tackles","interceptions","clearances","def_touches","at_touches","dribbles","good_dribles","fouls_drawn","areal_wins","dribbles_goal","goal_action","shots_target")

dim(players.df)
```

Then if we work with the current data, knowing that all of the variables are per games except for matches_started, we need to get rid of the player that did not play a lot because this will only bring noise. We don't take into account player that have played less than 10 min per game in the season. With this operation we lose 1290 rows! Which mean a lot of rows were "useless" knowing that 10 min per game really isn't a lot.
```{r}
players  = players  %>% filter( min_played > 10)
players.df  = players.df  %>% filter( min_played > 10)
```

## Missing values

With the current data frame we don't have any missing values,note that there are some in the raw data.
```{r}
barplot(colMeans(is.na(players.df)), las=3)
dim(players.df)
```

## Outliers
There is a high variability with certain variables but we can work with it since the data set is very large, the data seems realistic even thought there are a few relatively high values remaining. It seems like the data set is quite clean after the feature engineering because there are clearly extreme values in the raw data set. Once again, I don't see the need to add something here.

```{r}
summary(players.df)
```

## Vissualization
Let's take a look at the data set, it has 1631 lines, or players and 21 variables. We can take a quick look with a general box plot and another one with scale values.
```{r}
boxplot(players.df, las = 2)
boxplot(scale(players.df), las = 2)
```


If we take a look at the correlations between variables, some are highly or totally correlated (positively). This is the case for 1 the number of matches started and the number of minutes played, 2 The passes and good passes,3 the shots, goals and shots on target, 4 tackles and good tackles and on and on... These correlations are logical and indicate that the data set seems realistic. Obviously the player who have most tackles passes and dribbles are going to be those who have respectively the most good tackles, good passes and good dribbles. We can note 2 negative high correlations that are interesting, the number of defensive touches with the number of shots and the number of attacking touches, this is a manifestation of the position of the players. 
```{r}
ggcorr(scale(players.df),label = T)
```


# Principal Component Analysis

We do the PCA analysis by scaling the data, in order to get the contribution of every variable fairly. X is going to be or scale data in the rest of the notebook.
```{r}
X = scale (players.df)
pca = prcomp(X)
pca
```

PCA needs a few components to describe a big chunk of the data set. With the first 4 variables we have 72.2%  of the initial information, with 6 variables we have more than 80% of the data. To get an important share of the information we're going to analyse the 6 first principal components. We reduce the dimension from 21 to 6 while keeping more than 80% of the data with the pca.

```{r}
fviz_screeplot(pca, addlabels = TRUE)
```

The 1st PC clearly describes an offensive player (with negative values), it gives importance to all the offensive qualities of the players like dribbles, attacking touches and goals. The defensive variables have a positive contribution to this PC. If we take a look at the five 5 players with this PC we find "Kylian Mbappé"   "Vinicius Júnior" "Ousmane Dembélé" "Mohamed Salah"   "Luis Muriel". 3 of them are in the top 10 ranking of the balon d'or for that season and all of them are recognize as being world class offensive players.
```{r}
barplot(pca$rotation[,1], las=2, col="gold")
players$name[order(pca$x[,1])][1:10]
players$position[order(pca$x[,1])][1:10]

```

The 50 last players for that pc are all defenders!
```{r}
players$position[order(pca$x[,1])][(length(players$position)-49):length(players$position)]
```

The second PC gives importance (with negative values) to all type of qualities a player can have like tackles, passes, interceptions... This PC would be something like the most useful or complete player to a team. By taking a look at the 20 best player for that PC we see there is no one position that is present in a significantly large amount between defenders and midfielders. There basically no or very few forward players or goalkeepers in the firsts positions of that pc.
```{r}
barplot(pca$rotation[,2], las=2, col="gold")
players$name[order(pca$x[,2])][1:20]
players$position[order(pca$x[,2])][1:20]
```

The third PC doesn't highlight a particular skill, it only give information for the most used players. The most used being Kylian Mbappe which is not a surprise since he is very young, he picked up only very short injuries and started 34 out of 38 games in the season.
```{r}
barplot(pca$rotation[,3], las=2, col="gold")
players$name[order(pca$x[,3])][(length(players$name)-9):length(players$name)]
players$position[order(pca$x[,3])][(length(players$position)-9):length(players$position)]
```

The fourth PC talks about pure forward striker skills, with big emphasis with skills like goals, shots on target and areal wins. Out of the 10 best players for that PC 9 are strikers. It gives importance to the physical ability (implicitly with areal wins) of a player that's why only tall people are present in this list.
```{r}
barplot(pca$rotation[,4], las=2, col="gold")
players$name[order(pca$x[,4])][1:10]
players$position[order(pca$x[,4])][1:10]
```

The fifth and sixth are harder to explain but it seems like the 5th describe players that have great passing skills and the 6th players that create goal action by dribbling.
```{r}
barplot(pca$rotation[,5], las=2, col="gold")
players$name[order(pca$x[,5])][1:10]
players$position[order(pca$x[,5])][1:10]
barplot(pca$rotation[,6], las=2, col="gold")
players$name[order(pca$x[,6])][1:10]
players$position[order(pca$x[,6])][1:10]
```


With the next plot we have the player with best offensives skill to the right and the best general skills to the top, the pc3 give the information on how much was the player used. We can note that at the bottom left there is a cluster of goalkeepers they "don't have" any offensive skill nor general skills. The 1st point is obvious but the second one is less obvious but we can explain it because in the data frame no variables actually describe goalkeeper abilities. It is difficult to give an interpretation for the use of a player since a player can play or not because of issues unrelated to his performances.
```{r}
data.frame(z1=-pca$x[,1],z2=-pca$x[,2]) %>% 
  ggplot(aes(z1,z2,label=players$name,color=pca$x[,3])) + geom_point(size=0) +
  labs(title="PCA", x="Offensive skills", y="General skills")+theme_bw() + scale_color_gradient(low="yellow", high="red")+theme(legend.position="bottom") + geom_text(size=2, hjust=0.6, vjust=0, check_overlap = TRUE) 

data.frame(z1=-pca$x[,1],z2=-pca$x[,2]) %>% 
  ggplot(aes(z1,z2,label=players$position,color=pca$x[,3])) + geom_point(size=0) +
  labs(title="PCA", x="Offensive skills", y="General skills")+theme_bw() + scale_color_gradient(low="yellow", high="red")+theme(legend.position="bottom") + geom_text(size=2, hjust=0.6, vjust=0, check_overlap = TRUE) 
```

With the PCA we're going to be able to identify the position of a player using the 2 firsts pc, being very high in the pc1 makes you a forwards player while being very low makes you a defender. The other players will most likely have a high value for the pc2 hat will make them middle field players. The pc3 doesn't really help us to fulfill our goal. Having a bad pc1 and 2 makes you a goalkeeper.

# Factor Analysis
## 4 factors
Once again we're going to use scaled data. We're going to chose 4 factors, this is because we can divide player by basic position : Goal keeper, Defensive player, Middle field player, Offensive player. With the 4 factors we see that 67.5% of the data is considered, so we drop 17 variables but still get close to 70% of the information.
```{r}
X_fa_an <- factanal(X, factors = 4, rotation="none", scores="regression",scale = T)
# Contribution des facteurs aux variables
X_fa_an$loadings
```


We see that here, the factor analysis give very similar result compared to the PCA, except for the 4th Factor, let's take a look at each of the four factor and at the 4 first pc. We see that for the 3 first the similarity is huge in the contribution of the key variables so we can give the same interpretation given for the pca. We have Factor 1 that highlight offensive skill, Factor 2 that highlight general skills and the third one that give an emphasis on how much was the player used. 
```{r}
par(mfrow=c(1,2))
barplot(X_fa_an$loadings[,1], las=3, col="gold")
barplot(-pca$rotation[,1], las=3, col="gold")

barplot(X_fa_an$loadings[,2], las=2, col="gold")
barplot(-pca$rotation[,2], las=2, col="gold")

barplot(X_fa_an$loadings[,3], las=2, col="gold")
barplot(pca$rotation[,3], las=2, col="gold")

```

The pc4 and the factor 4 are clearly different while pc4 gives importance to striking and physical abilities, the factor 4 give positive importance to tackles while giving a negative importance to defensive touches and passes. We really don't get any information on positions with the 4th factor.
```{r}

barplot(X_fa_an$loadings[,4], las=2, col="gold")
barplot(-pca$rotation[,4], las=2, col="gold")

```

## 3 Factors
Since the 4th factor doesn't seem very helpful we can also try with 3 factors but now we only have 57% of the data. The first factor is always very similar to the pc1. Same thing for the Third factor an d pc3 but there are important differences with the second pc.
```{r}
X_fa_an <- factanal(X, factors = 3, rotation="none", scores="regression",scale = T)
```

Comparing pc1 and factor 1 then pc3 and factor 3 we can see the similarities.
```{r}
barplot(X_fa_an$loadings[,1], las=3, col="gold")
barplot(-pca$rotation[,1], las=3, col="gold")

barplot(X_fa_an$loadings[,3], las=2, col="gold")
barplot(pca$rotation[,3], las=2, col="gold")
```

PC2 is very broad and general, however Factor 2 emphasis a lot the passing and negatively emphasis playing a lot. This would describe someone does not play a lot but that is still efficient and useful for the team. This might be the middlefield players.
```{r}
barplot(X_fa_an$loadings[,2], las=2, col="gold")
barplot(-pca$rotation[,2], las=2, col="gold")
```

## 2 Factors
We can also try with 2 factors but now we only have 49.7% i.e. half of the data. The first factor is once again very similar to the pc1. The second is somewhat similar to pc2, except it is less intense in most of the variable but much more in the passing (positively) and in the play time (negatively).
```{r}
X_fa_an <- factanal(X, factors = 2, rotation="none", scores="regression",scale = T)
```

```{r}
barplot(X_fa_an$loadings[,1], las=3, col="gold")
barplot(-pca$rotation[,1], las=3, col="gold")

barplot(X_fa_an$loadings[,2], las=2, col="gold")
barplot(-pca$rotation[,2], las=2, col="gold")

```

With 4 factors and 2 factors we can guess position of players like we do with the pca, start by rating the offensiveness of the player with factor 1 and then evaluate if the player has middle fielder skills else his will be a goal keeper.

# Clusters
## k -means
### K - means 4 centers
Let's start the clusters wit the k-means, we're going to use 4 clusters initially for the 4 positions and see what happens. The football teams have many players for each position but have more middle field players, less goal keeper and a similar amount of defensive and offensive player even thought they tend to have more offensive players than defensive players. We can take a look at the groups of players in the clusters and deduce which position is described using that logic.
```{r}
fit.4 = kmeans(X, centers=4, nstart=100)
groups.4 = fit.4$cluster
par(mfrow=c(1,1))

barplot(table(groups.4), col="gold")

```

Once center gives importance to defensive variables like interception, clearance and areal wins.
Another de-emphasis all variables except the game played and the defensive touches, this is clearly a description of goalkeepers.
A third one give an emphasis to basically all the variables especially passes tackles and assists (compared to the mean) this correspond to mid-fielders or generally useful players for the team.
finally for the last one all the offensives qualities are highlighted goals,shot,dribbles...

```{r}
centers4=fit.4$centers
# Center 1 : 
bar1=barplot(centers4[1,], las=2, col="gold")
points(bar1,y=apply(X, 2, quantile, 0.50),col="red",pch=13)
```

fit.4 = kmeans(X, centers=4, nstart=100)
groups.4 = fit.4$cluster
centers4=fit.4$centers
# Center 1 : 
bar1=barplot(centers4[1,], las=2, col="gold")
points(bar1,y=apply(X, 2, quantile, 0.50),col="red",pch=13)

```{r}
  # Center 2 :
bar1=barplot(centers4[2,], las=2, col="gold",)
points(bar1,y=apply(X, 2, quantile, 0.50),col="red",pch=13)
```


```{r}
# Center 3 : 
bar1=barplot(centers4[3,], las=2, col="gold")
points(bar1,y=apply(X, 2, quantile, 0.50),col="red",pch=13)
```

```{r}
# Center 4 : 
bar1=barplot(centers4[4,], las=2, col="gold")
points(bar1,y=apply(X, 2, quantile, 0.50),col="red",pch=13)

```

With the following plot we see the our assumptions are confirmed, the cluster indeed indicate position, we can look at some players in the plot to see that.

This doesn't mean that there can't be some mistakes in the classification but overall it seems very good.
```{r}
fviz_cluster(fit.4, data = X, geom = c("point"),ellipse.type = 'norm', pointsize=1)+theme_minimal()+geom_text(label=players$position,hjust=0, vjust=0,size=2,check_overlap = T)+scale_fill_brewer(palette="Paired")

```


We can take a look at the silhouette with 4 clusters.
```{r}
d <- dist(X, method="euclidean")  
sil = silhouette(groups.4,d)
plot(sil, col=1:4, main="", border=NA)
```

### K-means how many cluster should be chosen?
So previously we made an hypothesis on the number k let's try to chose the best possible one, there is no optimal way to take that decision since we're in the domain of unsupervised learning.

Let's start by taking a look at the silhouette for different k. This method clearly prefers the value k = 3, the division in plane words would possibly be something like offensive player, defensive player and goal keeper.
```{r}
fviz_nbclust(X, kmeans, method = 'silhouette')
```

With the within sum of square method we see that the elbow appears quite explicitly at number 4 which is the value of k we started with.
```{r}
fviz_nbclust(X, kmeans, method = 'wss')

```

With gap statistic method we see that the best number for k should be 3.
```{r}
fviz_nbclust(X, kmeans, method = 'gap_stat', k.max = 20)

```

Since the gap statistics and the silhouette method agree with each other plus we have already found a possible explication for that division we're going to use k-means with k=3. The division we talked about is the one we see in the cluster plot. The offensively inclined players, the defensively inclined players and the goalkeepers.
```{r}
fit.3 = kmeans(X, centers=3, nstart=100)
groups.3 = fit.3$cluster
centers3=fit.3$centers

fviz_cluster(fit.3, data = X, geom = c("point"),ellipse.type = 'norm', pointsize=1)+theme_minimal()+geom_text(label=players$position,hjust=0, vjust=0,size=2,check_overlap = T)+scale_fill_brewer(palette="Paired")


# Center 1 : 
bar1=barplot(centers3[1,], las=2, col="gold")

# Center 2 : 
bar1=barplot(centers3[2,], las=2, col="gold")

# Center 3 : 
bar1=barplot(centers3[3,], las=2, col="gold")


```

For our purpose of classifying player's position it might actually be better to keep 4 clusters because the 4th is quite efficient in classifying a middle fielder, by using 3 clusters we lose that information or rather we make it difficult to classify a player as MF.

### K-means with the multivariate standardization

We're now going to use k-means with the mahalanobis distance instead of the euclidean distance. We're going to keep working with 4 clusters.
```{r}
S_x <- cov(players.df)
iS <- solve(S_x)
e <- eigen(iS)
V <- e$vectors
B <- V %*% diag(sqrt(e$values)) %*% t(V)
Xtil <- scale( players.df,scale = FALSE)
playerS <- Xtil %*% B

fit.mahalanobis = kmeans(playerS, centers=4, nstart=100)
groups = fit.mahalanobis$cluster
centers=fit.mahalanobis$centers
colnames(centers)=colnames(X)

fviz_cluster(fit.mahalanobis, data = X, geom = c("point"),ellipse.type = 'norm', pointsize=1)+theme_minimal()+geom_text(label=players$position,hjust=0, vjust=0,size=2,check_overlap = T)+scale_fill_brewer(palette="Paired")

```

The clusters with the 2 methods seems very similar, and we can say it is the case by looking at they similarness. 0.69 is close to 1 we can say that with both methods we have a similarity of 69%.
```{r}
adjustedRandIndex(fit.4$cluster, fit.mahalanobis$cluster) 
```

## Kernel K-means

Let's use the K-means kernel method with the scaled data, it is very interesting to see that compared to the classical k-mean method with 4 centers we have a 84% m=similarity. We also see with the plot that we quite clearly see the clusters and the positions are related.To be simplistic we have FW on the left DF on the right and MF in the middle and then the GK isolated on the corner.
```{r}
fit.ker <- kkmeans(as.matrix(X), centers=4, kernel="rbfdot") 

#centers(fit.ker)
#size(fit.ker)
#withinss(fit.ker)

object.ker = list(data = X, cluster = fit.ker@.Data)
fviz_cluster(object.ker, geom = c("point"), ellipse=F,pointsize=1)+
  theme_minimal()+geom_text(label=players$position,hjust=0, vjust=0,size=2,check_overlap = T)+scale_fill_brewer(palette="Paired")

adjustedRandIndex(fit.4$cluster, fit.ker) 
```



## PAM
Continuing with clustering methods we can try with partitioning around medoids with 4 centers, using the scaled data. This method give similar results, it has a similarity of 67% with the k-means method and 76% similarity with the kernel k-means method (when I launched the code).
```{r}
fit.pam <- eclust(X, "pam", stand=TRUE, k=4, graph=F)

fviz_cluster(fit.pam, data = X, geom = c("point"), pointsize=1)+
  theme_minimal()+geom_text(label=players$position,hjust=0, vjust=0,size=2,check_overlap = F)+scale_fill_brewer(palette="Paired")

adjustedRandIndex(fit.4$cluster, fit.pam$clustering) 
adjustedRandIndex(fit.ker, fit.pam$clustering) 

```


## Hierarchical clustering
Now let's take a look at Hierarchical clustering. note that the size of th data make the plots very long on my pc even if I cut the data in half, so we're only going to focus on the heatmap. We can take from that plot that there are 3 main separations in the variables, the offensive one going from shots to assists grouped together, the defensive one going from def_touches to areal_wins grouped together and between them is the play time variables. These chunks give a clear indication on the position a player.  
```{r}
d = dist(X, method = "euclidean")
hc <- hclust(d, method = "ward.D2") 


"""
hc$labels <- players$names
#Loading time way too long...
fviz_dend(x = hc,
          k = 4,
          color_labels_by_k = TRUE,
          cex = 0.8,
          type = 'phylogenic',
          repel = TRUE) + theme(axis.text.x=element_blank(),axis.text.y=element_blank())+geom_text(label=players$name,hjust=0, vjust=0,size=2,check_overlap = F)
      
fviz_dend(x = hc,
          k = 4,
          color_labels_by_k = TRUE,
          cex = 0.8,
          type = 'phylogenic',
          repel = TRUE)+ theme(axis.text.x=element_blank(),axis.text.y=element_blank())
"""



heatmap(X,
        distfun = function(x){dist(x, method = "euclidean")},
        hclustfun = function(x){hclust(x, method = "ward.D2")},
        cexRow = 0.7)
```

## EM clustering
Finally we can take a look at expectation maximization clustering, a more probabilistic method. Using BIT the optimal number of center is 6, and one we plot it seems like have overall two clusters for GK, two for MF, one for DF and one for FW, but by looking carefully we see that there are a lot of inconsistent values for our purpose of guessing the position, so this method would not be efficient for us. 
```{r}
res.Mclust <- Mclust(X)
summary(res.Mclust)

fviz_mclust(object = res.Mclust, what = "BIC", pallete = "jco") +
  scale_x_discrete(limits = c(1:10))

fviz_mclust(object = res.Mclust, geom = "point",
            pallete = "jco")+geom_text(label=players$position,hjust=0, vjust=0,size=2,check_overlap = T)
```

# Conclusion
Trying to guess the real are best position of a player looking at it stats/game seems to work using most of the above tools, we can clearly see which for each position who excels the most but we still have to keep in mind that those stats have a enormous bias because you won't have the ability to express certain skills in certain position, imagine if we have a very good striker but the coach decides to play him defender we wouldn't be able to see where he plays best because his stats would mainly reflect the defensive responsibilities he has, this is the main problem with this data set analysis.

# Inspirations :
- All the notebooks seen in labs
